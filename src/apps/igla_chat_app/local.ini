[server]
host = 0.0.0.0
port = 8002

[elasticsearch]
url = http://localhost:9200
index_prefix = local

[vector_store]
embeddings_type = hugging_face

[logging]
level = INFO
format = %(asctime)s %(levelname)s %(message)s

[chat]
chat_model_type = hugging_face
llm_hf_model_path = /home/nikolaypavlychev/llm4search_dev/llm4search_dev/llm4search/models/saiga_large/saiga_mistral_7b-GPTQ
task = text-generation
max_new_tokens = 800
top_p = 0.95
top_k = 100
temperature = 0.05
repetition_penalty = 1.1
